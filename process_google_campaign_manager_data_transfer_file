# Import Pandas and Numpy


import pandas as pd # import pandas
import numpy as np # import numpy


# Import the auto-generated daily activity-log from Google Cloud Storage


original_dt_file = pd.read_csv('dcm_advertiserxxxxxxx_xxxxxxx_activity_2019xxxx_2019xxxx_xxxxxx_xxxxxxxxxx.csv.gz', compression='gzip', header=0, sep=',', error_bad_lines = False)        
original_dt_file.head(5) # check if the file is imported correctly


# Extract 5 columns that we need for the incrementality test analysis


needed_columns = pd.DataFrame([original_dt_file['Event Time'], original_dt_file['Interaction Time'], original_dt_file['Campaign ID'], original_dt_file['Activity ID", original_dt_file['Event Sub-Type']]) #I need 4 columns to prepare the raw_data for the incrementality test: "Event Time", "Campaign ID", "Interaction Time", "Activity ID", "Event Sub-Type". I need to populate these columns from the original file one by one
columns_df = pd.DataFrame.transpose(needed_columns)


# Extract data for test-campaign and placebo-campaign


test_campaign =  columns_df['Campaign ID'] == 21yyyyy32 # filter rows for "test_campaign" using  the boolean variable
test_campaign_only = columns_df[test_campaign] #filter rows for "test_campaign" using  the boolean expression
placebo_campaign =  columns_df['Campaign ID'] == 21zzzzz32 
placebo_campaign_only = columns_df[placebo_campaign] 
test_and_placebo = pd.concat([test_campaign_only, placebo_campaign_only]) # concatenate 2 campaigns together


# Extract data for the 4 purchase-activity


convo_1 = test_and_placebo["Activity ID"] == 7245096
convo_2 = test_and_placebo["Activity ID"] == 7305055
convo_3 = test_and_placebo["Activity ID"] == 7252068
convo_4 = test_and_placebo["Activity ID"] == 8669579 # Purchase-fastcheckout floodlight, not live yet
convo_1_only = test_and_placebo[convo_1]
convo_2_only = test_and_placebo[convo_2]
convo_3_only = test_and_placebo[convo_3]
convo_4_only = test_and_placebo[convo_4]
test_and_placebo_convos = pd.concat(test_and_placebo[convo_1_only, convo_2_only, convo_3_only, convo_4_only]) # concatenate all 4 purchase activities together


# Calculate the time_lag between event time (when a transaction is generated) and interaction time (when an impression occured)


event_time = pd.to_datetime(test_and_placebo_convos['Event Time'],unit='us') # transform unix code to datetime format
interaction_time = pd.to_datetime(test_and_placebo_convos['Interaction Time'],unit='us')
time_lag = (event_time - interaction_time) / np.timedelta64(1,"s") # turn days into seconds


# Create a new dataframe for incrementality test analysis in Excel


test_and_placebo_df = pd.DataFrame(test_and_placebo_only["Campaign ID", time_lag, "Event Sub-Type"])
test_and_placebo_ready = pd.DataFrame.transpose(test_and_placebo_df)
test_and_placebo_ready.to_csv('test_placebo_date.csv',index=False)
