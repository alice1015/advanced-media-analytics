import pandas as pd
import glob


# Use glob to extract all files with the same naming convention, and check if all files are processed

imps_raw_0803 = glob.glob('dcm_advertiser*******_*******_impression_20190803*.csv.gz')
len(imps_raw_0803)


# Write a for-loop to read all the .csv.gz and concatenate them together.

df_placeholder = pd.DataFrame()

for eachfile in imps_raw0803:
    imps_raw_0803 = pd.read_csv(eachfile, compression='gzip', header=0, sep=',', error_bad_lines = False)
    imps_0803 = pd.concat([df_placeholder,imps_raw_0803])
    df_placeholder = imps_0803
   
   
# build a new activity_dataframe with transaction-activity only

activity_0803.rename(columns = {'Activity ID':'activity_id'}, inplace = True)
trans_0803 = activity_0803.query('activity_id == xxxxxxx or activity_id == yyyyyyy or activity_id == zzzzzzz')


# how many unique users that are in both activity and impression file

len(set(trans_0803['User ID']))
len(set(imps_0803['User ID']))
len(set(trans_0803['User ID']) & set(imps_0803['User ID']))


# add a dummy column to trans_0803
trans_0803_['dummy_col'] = 1

# merge trans_0803 and imps_0803 where "User ID"s are identical
# use a left join so when imps_0803 and trans_0803 match on the user-ID fields
# the dummy_col will have value of 1, otherwise Null
matched_users_0803 = (
    imps_0803
    .merge(
        trans_0803[['User ID', 'dummy_col']],
        left_on='User ID',
        right_on='User ID',
        how='left'
    )
)

# replace null values (i.e. those where the join did not work) with `
matched_users_0803['dummy_col'] = matched_users_0803['dummy_col'].fillna(0)


val = results['dummy_col'].sum() 
print(val)
